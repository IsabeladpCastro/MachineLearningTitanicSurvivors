{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0TpYrHMTyGWV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wPM2Mvq_uS6Y"
      },
      "outputs": [],
      "source": [
        "#Importar bibliotecas\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Carregar dataset Titanic\n",
        "df = sns.load_dataset(\"titanic\")\n",
        "print(\"Dataset carregado!\")\n",
        "print(df.head())\n",
        "print(df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MCGGorsunv3",
        "outputId": "93d52bf5-24a8-4496-b419-06f665b50f08"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset carregado!\n",
            "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
            "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
            "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
            "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
            "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
            "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
            "\n",
            "     who  adult_male deck  embark_town alive  alone  \n",
            "0    man        True  NaN  Southampton    no  False  \n",
            "1  woman       False    C    Cherbourg   yes  False  \n",
            "2  woman       False  NaN  Southampton   yes   True  \n",
            "3  woman       False    C  Southampton   yes  False  \n",
            "4    man        True  NaN  Southampton    no   True  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 15 columns):\n",
            " #   Column       Non-Null Count  Dtype   \n",
            "---  ------       --------------  -----   \n",
            " 0   survived     891 non-null    int64   \n",
            " 1   pclass       891 non-null    int64   \n",
            " 2   sex          891 non-null    object  \n",
            " 3   age          714 non-null    float64 \n",
            " 4   sibsp        891 non-null    int64   \n",
            " 5   parch        891 non-null    int64   \n",
            " 6   fare         891 non-null    float64 \n",
            " 7   embarked     889 non-null    object  \n",
            " 8   class        891 non-null    category\n",
            " 9   who          891 non-null    object  \n",
            " 10  adult_male   891 non-null    bool    \n",
            " 11  deck         203 non-null    category\n",
            " 12  embark_town  889 non-null    object  \n",
            " 13  alive        891 non-null    object  \n",
            " 14  alone        891 non-null    bool    \n",
            "dtypes: bool(2), category(2), float64(2), int64(4), object(5)\n",
            "memory usage: 80.7+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Pré-processamento\n",
        "#Selecionar features e target com cópia explícita\n",
        "features = [\"pclass\", \"sex\", \"age\", \"sibsp\", \"parch\", \"fare\", \"embarked\"]\n",
        "target = \"survived\"\n",
        "\n",
        "X = df[features].copy()\n",
        "y = df[target].copy()\n",
        "\n",
        "#Tratar valores faltantes usando atribuição direta\n",
        "X[\"age\"] = X[\"age\"].fillna(X[\"age\"].median())\n",
        "X[\"embarked\"] = X[\"embarked\"].fillna(X[\"embarked\"].mode()[0])\n",
        "\n",
        "#Transformar variáveis categóricas\n",
        "X = pd.get_dummies(X, columns=[\"sex\", \"embarked\"], drop_first=True)\n",
        "\n",
        "#Conferir dados tratados\n",
        "print(X.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJZ6oMhsvCky",
        "outputId": "8b5bded5-f1da-41ff-a5eb-cb7087371438"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   pclass   age  sibsp  parch     fare  sex_male  embarked_Q  embarked_S\n",
            "0       3  22.0      1      0   7.2500      True       False        True\n",
            "1       1  38.0      1      0  71.2833     False       False       False\n",
            "2       3  26.0      0      0   7.9250     False       False        True\n",
            "3       1  35.0      1      0  53.1000     False       False        True\n",
            "4       3  35.0      0      0   8.0500      True       False        True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Separar treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "print(f\"Tamanho treino: {X_train.shape}, Tamanho teste: {X_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwT5N7MfwGtG",
        "outputId": "73fb3a8d-1f5d-44cd-a3ae-0ac53f64a3b2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho treino: (712, 8), Tamanho teste: (179, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Treinar modelos\n",
        "#Regressão Logística\n",
        "lr = LogisticRegression(max_iter=1000)\n",
        "lr.fit(X_train, y_train)\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "\n",
        "#Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)"
      ],
      "metadata": {
        "id": "26fdrreKxGjl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Avaliar modelos\n",
        "\n",
        "print(\"=================== Logistic Regression ===================\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
        "print(classification_report(y_test, y_pred_lr))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_lr))\n",
        "\n",
        "print(\"\\n===================== Random Forest ======================\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDpD4qvdxQ8L",
        "outputId": "8e091ea1-ccb1-4608-86eb-dfe4610ac52b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================== Logistic Regression ===================\n",
            "Accuracy: 0.8100558659217877\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.86      0.84       105\n",
            "           1       0.79      0.74      0.76        74\n",
            "\n",
            "    accuracy                           0.81       179\n",
            "   macro avg       0.81      0.80      0.80       179\n",
            "weighted avg       0.81      0.81      0.81       179\n",
            "\n",
            "Confusion Matrix:\n",
            " [[90 15]\n",
            " [19 55]]\n",
            "\n",
            "===================== Random Forest ======================\n",
            "Accuracy: 0.8212290502793296\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.87      0.85       105\n",
            "           1       0.80      0.76      0.78        74\n",
            "\n",
            "    accuracy                           0.82       179\n",
            "   macro avg       0.82      0.81      0.81       179\n",
            "weighted avg       0.82      0.82      0.82       179\n",
            "\n",
            "Confusion Matrix:\n",
            " [[91 14]\n",
            " [18 56]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Conclusão\n",
        "if accuracy_score(y_test, y_pred_rf) > accuracy_score(y_test, y_pred_lr):\n",
        "    print(\"\\nRandom Forest teve melhor desempenho.\")\n",
        "else:\n",
        "    print(\"\\nRegressão Logística teve melhor desempenho.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fdIiZ5oxlER",
        "outputId": "c61367b6-8a13-4491-d7c7-5ef636ca0e30"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Random Forest teve melhor desempenho.\n"
          ]
        }
      ]
    }
  ]
}